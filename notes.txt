What operations and forms are NOT quantified?
Q represents a quantified sub-program,
(x : T), (x)
What operations are quantified over the sub-program.
{(x : T), (x)}
does this result in a quantification of collections?
What if I want to specify the quantification of a collection?
The type of a collection of a bunch of things
what about a sequence?
A, B, Q
Q, A, B
((x : T), (x)), A, B
quantify over side effects?
yes.
Q, A, B
(f (g (h ((x : T), x))))
so in this case the quantification is propagated
How would I make a sequence by quantified?
(x : T), ((A, B, x), C)



how to create operations that do not affect context?
Macros don't affect context by default.
or do i need that if i have closures?
because closures capture everything.
Also i dont want to capture too small of a tree.
how would i implement green threads?
well you'd have to call a function that captures the continuation.
So there's a list of threads, a scheduler, and a function to capture a point and switch to another thread.
What does that look like?
You can turn all of them into a yield function over a list of continuations.
(threads <- {}),
(yield <- (c -> ))


I'd like to make an in-place insert operation.
(({1 3} \\ 1 2) = {1 2 3})


What if there's an expression which accepts anything?
Does that allow quantification?
(<- ((n : {'m *}) -> (f (n \ 2))),
(m (1 + Nat))
What about quantification as iteration?
Loop incrementing an array

how to loop?
Do I do tail call optimization? yes
can I also just do continuations? yes

(countdown <- (i -> (? (i > 0) (& <- (countdown (i - 1)) i))))
(countdown <- (i -> (? (i > 0) (countdown (i - 1)) i)))
(countdown <- (i -> (& \ 0 '(? (i > 0) (& <- (i <- (i - 1))) i))))
named let is such a convenient form. 
what's the equivalent of named let?
(& <- (loop <- `(a, (& <- loop))))
is there no equivalent of named let?
No but you can make it pretty easily.
((e : {'loop Symbol Expression}) -> ((e \ 1) <- (e \ 2)), (! (e \ 1)))



lets say I want to take the context so that I can always get a value back.
Contexts are bound by functions.
New functions create new contexts.
So when I use '&, it's referring to the immediate function context.
But it's not actually, it's referring the rest of the program.
So then how would I do threads?
use a FIFO proc list.

threads <- {}

sticking point, if the function boundary is the prompt, then what happens when 
you take the context at different points?
(f <- (x -> &, (g x), &, (h x))
it all equals the lambda with fixed arguments.
How to loop
(countdown <- (n -> 
	(? (n > 0) 
	   (n ~ (n - 1)), (& <- &)
	   n)))
or does it set control to a specific point?
what about returning, can you exit to a different place?
In a sequence, the context is the position at the sequence so 
(a, (x <- &), b, c, (y <- &), d)
((x \ 0) = (b, c, d))
((y \ 0) = (d))



Say I define some function on a collection and i call it 
(f <- ((n : Collection) -> n + {0})),
(f (1 2))
how does it know to treat '(1 2) as an expression not a collection?
type tags.
(1 2) is not the same as {1 2} because there's a type tag.



how to do pointers with one symbol?
there's two operations: derive the location of some data and refer to a location
@ is pointer operations.
trivial ((@ (@ x)) = x)
that looks nice
what about taking the address of a location?
(x <- (@ y)),
((@ x) = y)
if it's possible to take the address of an address then i can do it.
I have to do some type-level wrenching to do it.
((: y) = Location), (@ (y : *))
you can't upcast.
how to get the address of an address?
there's two types of the expression, 
[({'@ *} -> Location) ({'@ Location} -> *)]
what I need is ({'@ Location} -> Location)
so what kind of type-level wrenching can do this?
if I expect a location, then thats the operation that's applied
so now I have 
(({'@ *} -> Location) : Location)
(({'@ Location} -> *) : *)
(({'@ Location} -> Location) : Location)



where to use period?
its used as a decimal point in a symbol.
1.1
what notation should it be used for?
composition?
(f : Function), (g : Function), ((f . g) : Function)
use it to terminate a bunch of closing braces.
No that's harder to read.
Actually should I use it to look up names?
dot can be used as subscript or name lookup
it's overloaded based on whether you're handing it a number or a symbol.
(m <- {(x <- 1) (y <- 2) (z <- 3)}),
((m . 1) = 1),
((m . 'x) = 1)
no this sucks


Whats my syntax?
(math <- ({Number} + ['+ '- '* '/ '//] + [{Number} math]))
(logic <- ([{Boolean} {'- Boolean}] + ['/\ '\/] + [{Boolean} {'- Boolean} logic])
(collection-algebra <- ({Collection} + ['+ '- '/] + [{Collection} collection-algebra]))
(type-algebra <- ({Type} + ['+ '- '/] + [{Type} type-algebra]))
(access <- {'. [Number Symbol access]}), {Collection} + access
{Collection '. Symbol}
{Collection '/ *}
{Collection *}
({Symbol} * Collection + {'->} + Expression)
(Function + Collection)
{'@ *}
{'@ Location}
{Number ['< '>] Number}
{Type ['< '>] Type}
{* '= *}
{'? Boolean Program Program}
{'? Boolean Program}
(data <- {'|} + [{*} {* Natural}] + [{'|} data])



What are my basic types?
- Number
  - Integer
  - Natural
- Function
- Collection
  - Type
  - Expression
  - String
- Program
  - Expression
  - Symbol
- Character
- Data
  - Value
  - Reference
  - Byte



Is it possible to statically type code when you don't know the expression?
Depends.
I can verify functions just fine and same with lambdas, so it must be the same with contexts.
Contexts are lexical boundaries with lexical closures so stuff is only bound if it's declared lexically.
There's even syntax for it, (<- *)
So let's say I enter a function and I define a lambda and an expression.
(f : (n -> 
(<- ((e : {'a *}) -> (e . 2))),
(a 1)))
You can statically type if you have prior knowledge of the meaning of the code.
In a language like mine where the meaning of a phrase is completely contextual, you don't know.
It's equivalent to introducing a new word used in the next sentence.
That's fine in English and it's proven comprehensible by AI programs.
Should be fine here too.
Should I skip lisp though and just make a different kind?
I can make more node types than just the few involved in the Lisp AST.
Multi-typed AST.
That's the way to go.
An AST node with different semantics.
I can make a new constructor for it.
Can't be at the reader level though because the primitive reader only reads certain things.
That's okay though, I don't want every possible notation.
There's a difference between being able to conveniently extend syntax and having to include every possible syntax.



So it's impossible for a function to accept any expression and apply it.
This sucks.
In Lisp, everything is a function.
Maybe I'm doing it wrong.
Pattern matching over the structure of a thing without worrying about lookup or anything.
It's highly expressive, but difficult to interpret.
A faster interpreter would be a normal Lisp where you can dispatch on the first symbol reliably.
But I want an actual language, not a functional DSL.
I want to write variable sized math expressions (1 + 2 / 4 * 5)
I want to be able to write logic expressions (True /\ - False \/ True)
There's interleaved lookup though because you can't decide for any given context that a symbol is reserved as an operator.
This means that I can absolutely do (/\ <- True), (\/ <- False), ((/\ /\ /\) = /\)
No this isn't possible because symbols are resolved before the expression is evaluated so the previous expression would be {True True True} which isn't interpretable.
If a symbol isn't bound, then it's syntax.
That's a nice simple rule.



I need a data constructor so I can create vectors and segments of data.
That's (| Value | Value | Value | Reference | Byte 100 |)



where must a blank separate two things?
(Symbol Symbol) 
(Number Number)
If two Symbols or numbers are adjacent, they must be separated by a blank.




what's a program to read in a program model?
(-> 
 (program : _),
 (symbol : ""),
 (c : character),
 (c <- (read)),
 ({
   ((n : [Glyph Digit]) -> 
     (symbol <- (symbol + {c}))
   ((n : Blank) -> 
     (? (program = _) 
        (program <- symbol), (compute program)
	(? )))
((n : "(") -> )
((n : ")") -> )
((n : "[") -> )
((n : "]") -> )
((n : "{") -> )
((n : "}") -> )
((n : "\"") -> )
((n : "'") -> )
((n : Character) -> (error))
((n : _) -> (compute program))
} c)
)


how bad is it if I don't have complicated multiple operation forms?

What would be the type if I can't

(1 + (2 + ((3 - 1) / 1.5)))

Add together three collections
(Collection + (Collection + Collection))

logic problems
((True \/ True) /\ (False \/ True)) 
vs 
(True \/ True /\ False \/ True)



How do I talk about arrays?
I need a language for storage where I talk about how things are arranged spatially in the environment.
A Data language.
I can have a adjacent pair, or a vector.
This is different than a collection which is based on access and types.
Data has no type.
There's simple data and compound data.
Data is how you represent and organize information.
You have a single unit, a large unit, an a reference unit.
Call these 
Unit
Block
Reference

A Unit is the smallest single amount of data that can be stored.
A Block is the amount of data that can be operated on. It implies multiple 
A Reference is a unique abstract value corresponding to the location of a unit.
A Pair is to adjacent Data.
A Vector is a number of adjacent data.

Do I want the rest of the abstractions then? Yes.
It's nice that I have a language to talk about how things are represented, but
there's abstract concepts which should not be bound by format and storage requirements.
Or should they?
Yes.
The format of abstractions should be implementation dependent, but they should be extensible.
Or should I start from nothing with no type system?
That's dumb. I want a bunch of stuff built in.
There will always be some concept of digital storage.
My language is designed to be run on a computer rather than some abstract symbolic machine.
It's true that the symbolic part isn't even required.
But then how do you talk to the machine?



I don't like my language anymore.
There's a weird uncanny valley between the higher level abstractions and the lower level ones.
This should be fine though because I have functions to pass between each.
Also the point is that there is a sub-language to talk about how things are stored which is separate from the semantics of computation.
Just how there's a sub-language to talk about how numbers are worked.
This is actually suitable because you can make Unit, Block, and Reference be anything you need.



weirdness with the program model.
(1 + 1) ==> {1 '+ 1}
(({'a 'b} + {'c}) / 'b) ==> {{{'a 'b} '+ {'c}} / 'b}
Collections are part of the program model, but they're nominally typed as expressions.


How do I make undecideable syntax?
Easily.
(f : ((A) -> B)),
(f : ((A) -> C)),
(g : ((B) -> A)),
(g : ((C) -> A)),
(g (f A))
This is quantification though.
Do I need quantification? Yes.



Should I have two different languages for structuring data?
Yes because one kind of structure is about access an indirection, the other kind
is about relative position.
When I talk about data, I have a Unit, a Reference, and a Block.
A Block is some combination of Units and References.
Unit, Value, Register, Block.
A Block is made up of Units, Values, and Registers.
It is either a pair of adjacent data, or a vector of a single type of data.
(Unit | 100)
(Character : (Unit | 4))
(Character : Value)



Does a sequence form its own context? 
In other words, are the effects of the discarded expressions discarded as well as their results?
No. A sequence only means "this then finally that".
All of it occurs within the same context.
If you want to discard a context, then use a function,
((_ -> A, B, C)) 
that is a "code block"



What about effects?
I have a function, it does (f : (x -> x))
It doesn't affect anything, it just produces a value.
What about 
	(y <- 1), (f : (x -> (y <- x)))
that has an effect.
What about (f : (x -> (display x)))
that has an effect too.
I can't do effects because my language isn't abstracted from the effectful system.



Interfaces, Traits, and Typeclasses are ways to reason about the capabilities of a given abstraction.
"InTraClass" describes the idea of describing the capabilities of a type as the functions over it.
Take a type T, and an InTraClass M.
If M exposes the function f : M -> M, then 
f : T -> T means that T < M.
Normally InTraClasses are ad-hoc in that the implementations of the exposed 
capabilities can be defined at any point before the instantiation of the Intraclass is used.
Normal classes are not ad-hoc and the complete class definition must be given in a single declaration.
Interfaces and traits do not require this and only differ in classification of sub-type relations and inheritance.
I do not have interfaces because abstractions are not typed by the functions defined over them.

If I did want to make an Intraclass exposing a capability, I would have to write something like
Say I make some Intraclass "hash-able" with a capability "hash".
How would I make that for two types T and t such that both can be sub-types of hashable?
(T : Collection),
(t : Number),
(hash : ((T) -> Number)),
(hash : ((t) -> Number)),
(hashable : [(x : *), (? (hash x) x)])



How to talk about vectors?
[(m : Collection), (t : Type), (? ((:(m . (* : Number))) = t) m)]



how to talk about memory layout.
two things next to each other.
multiple of the same thing next to each other.
(Unit Unit)
(Unit 1000)
What if the model is a collection and then you instantiate data using the collection



how do I represent unbounded types?
should there even be a difference?
yes.
a quantified type is an unbounded type.
each type constructed is unique anyways.
so a continuous type is represented as a number of conditions which must be true.

(is-t <- (n -> (? (p /\ q /\ r) true false)))

so then do I need types at all?
is the type assertion even a part of the language or is it a macro?
It's a macro.
So is the debugger.
in fact, everything's a macro except for the basic language.
what about quantification?
nope.
what about simple type-checking for stuff like functions?
how do i do polymophism if the function doesn't work?
case matching.
you call the function on a case.
I am very stupid. Of course I need types.
Quantification is supposed to be one of the fundamental mechanics of my language.
If you can set a type constraint, then of course you can set a constraint without creating a variable binding.



how do I want to describe memory layout?
I want to talk about either two adjacent things or a thing that repeats.
i want to compose the two.


================================================================================
Matching algorithm--------------------------------------------------------------
================================================================================

let x be a value of type T.
Let there be a collection, m, with at least one element which is a function.
Take the collection, n, of all elements of m which are functions, (m / Function)
1. Search the collection for pre-images of the value x.
2. Search the collection for pre-images of the type T.
3. Search the collection for pre-images of a type where the value of x is the value of that type.


{1 2 3}
{Number Number Number}
(x : {Number Number Number})



A discrete or continuous type.
A discrete type is a collection of unique values.
A continuous type is a collection of conditions which must be true for a type.
I should be able to create a continuous type directly.
Here's some things that must be true.
That's just a refinement type though.
My type constructor is different. I can take the result of anything.

(m : Collection), (n : Number), (? ((:(m . n)) = K) m)

[[k]] is the same as [k]?
no because (x : [[k]]) is (x <- [k])
and (y : x), (y <- k)

so I can say 
(x <- (m : Collection), (n : Number), (? ((:(m . n)) = k) m))

so in (x <- (y <- 1), y)
does y persist in the context?
have I bound those?
I wish there was a way to make a temporary context.

(x <- ((_ -> (m : Collection), (n : Number), (? ((:(m . n)) = k) m))))



should quantification be effectful?
can I even make it effectful?
yes, via pointers.
(x <- {1}), (y <- (@ x)),
(n : ['a 'b 'c]), 
((* -> ((@ y) . 1 (((@ y) . 1) + 1))) n)
no because x is closed over and copied for each time the quantification is run.
it's not actually quantification if you can change what's true for each iteration.


What components of the language should not require arbitrary computation?
None, all facets of the language should allow arbitrary computations.
The langauge is simple enough where that's easy.
What about first class expressions?



A collection is not just a relation, it's also a resource constraint.
When a collection exists, so do all its elements.



I can't truly have higher order expressions... actually yes I can.
Expressions in my langauge are just maps between some syntax and some other syntax.
Unless I use compute, all functions are known because they can't be non-deterministically constructed.
Behavior may not be known, as in a polymorphic function, but that's okay.



I like the simplicity of cons pairs, but it's more efficient to use collections.
It supports vectors beyond a pair and random access.
Cons is actually implicit in the constructor.
(cons (cons 'a 'b) 'c) = {'a 'b 'c}
is an element separate or together with a collection?
That is to say, if a collection exists, does it imply that its elements exist?
YES IT DOES DON'T BE STUPID


I would love to express every algorithm in finite space and make resource allocation explicit.
Then I'm just left with C.
Especially with unrestricted dependent types, every stage of the computation process can require arbitrary space and time.



How do I make expressions that don't form their own contexts?
Or does each expression always have its own context?
Contexts can be discarded if they are never used.

What is {*}?
A collection containing anything.
How about [{*}]
the type of every collection containing anything.
((x : {*}) {0}) is this sound?



There's two types of types: discrete and continuous.
A discrete type can be represented as a listing.
A continuous type is represented as a program that verifies the type.
For a user-created continuous type, you have to specify the program which verifies the type.
What about quantification?
Saying for-all.
What if I can't use that?
Then I can't make refinement types.
So how do I make the type of numbers greater than 0?
Without quantification, I would have to make a recursive type like
(Couting <- []),(n -> (? (n > 0) (t + [n])), (n <- (n + 1)), (& <- &))
or I can say
(Counting <- ((_ -> (n : Natural), (? (n > 0) n))))
this is much more straightforward for a type definition.
I can get even easier,
(Counting <- (n : Natural), (? (n > 0) n))

Sequences form their own context.

(step1), (step2), (step3), (& <- &), (step4)
(n -> 
(n <- (n + 1))
(n <- (n + 1)))

What's the behavior when you call read?
you read in either a symbol, number, or a program which is computed to yield the read result.
you can also read in a character which reads in a single character of the character type.



how to make the type of an expression non-inferenceable?
Say an expression results in 1
what is non-inferenceable without using 'compute?
any non-recursive function stack is inferenceable.



what about skipping recursion?
Can I do that?
skipping recursion in favor of effects?
but i still want recursion.
how do I even do recursion?
the name inside the function is resolved after the name outside the function is resolved.
therefore when the function is engaged, it inherits the external binding of f.



what would a language look like that's not full of parentheses?

f = x in x + 1 .
f(1) .
y = 1, z = y  .
m = {1 2 y = 3 .} .
m / 1 .
n = m + {4} .
n = m .. 4 .

just more keywords that's all.
so could I define a language that's all keywords?

(f = (x y -> (x + y)))
f = x y -> x + y .


my language is harder than lisp. not everything is a list.
everything is a collection.
each collection has a counted number of elements.
Each element has a type.



what's my vector syntax?
(k .. n)
what's my matrix syntax?
(k .. n .. n)
how do I access them?
(V = ())
a matrix is just a vector with a length and a dimension.
it's an abstraction over vectors.
so I have a set, a vector, and a multiset.
do I need a vector if I can just have a multiset?
not really, all i need is a way of constructing a vector.
That's just 
(vector = (k n -> )

functions are control flow though so how do I take the context of a function before I enter into a sequence?
I use a sequence-less function definition.

(f = (k -> (m = &) m))

what's the type of a function then?

(+ (n : Nat), (Symbol .. n) 
   {'->}
   (m : Nat), (Expression .. m))

so if I want multiple

how to use | ?
Does it represent a type?
I have * _, but what about |
is that the context? no that's &
what about Any, Nil, Some?
no
what about data?
is it a block of data? no those are different sizes.
is it a storage type?
Unit type?
yes
Unit type is |
so now I can say
(Character = {| | | |})
oh that's actually kinda cool.
|__#_|
that describes a data



Nope, not doing it.



syntax?

sum		_ + _
		+ ...
difference	_ - _
		- ...
multiplication	_ * _
		* ...
division	_ / _
		/ ...
modulus		_ // _
disjunction	_ /\ _
conjunction	_ \/ _
negation	- _
constrain	_ : _
equality	_ = _
less		_ < _
greater		_ > _
less or		_ >= _
greater or	_ <= _
inequal		_ /= _
cardinality	# _
address		@ _
supertype	: _
function	_ -> _
collection	{ ... }
vector		_ .. _
type		[ ... ]
access		_ . _
application	_ _



what if storage types have special semantics.
what if I do a collection of {Byte Byte Byte}?
are these pointers to bytes? or actual bytes?
They're actual bytes.
storage types don't require indirection because they are stored directly.
even if I swap types around.



What fundamental capabilities do I need for my implementation?
I need the compute loop.
I need a matching function.
I need a constructor for each of the default functions.



What about qualitative types?
Say I want the type of a sorted collection.
It can be completly nominal.
(sorted = [Collection]),
(sort = ((M : Collection) -> sorted))



All expressions for all possible languages have a common grammar. 
What does this look like though?
Is it possible to simply talk?
No because you don't need multiple forms of each expression.
It's trivial to start with something more basic.
Is it possible to just use functions with no punctuation?
Not as long as there's macros.
f g h x
is fine but 
(f (g (h x))) 
works much better.
parens allow you to be extremely terse.
being terse is nice, but playing "code golf" like you do in the APL family obscures the meaning of the program.



<<<<<<< HEAD
unbounded types break the type system.
every primitive in the language should at least halt XD
Primitive types are always structural.
Because you can't quantify over a structure when all instantiations of a 
structure are structurally identical.
For instance: 
(T = {a b}),
(x = {a b}), (y = {a b})

what about refinement types though?
[(n : Number), (? (n < 10) n)]
[(f : Function), (n : Number), (f n)]
these require quantification and cannot be typed as a number.
Because a number is a structure.
Lets say
(T : [m n]),
(t = [(p : {T}), (? (p / m) p)])

What is the type of a number?
The constructor takes a symbol and converts it to a number.
(new-number : Function)
(Number : [(s : Symbol), (new-number s)])



<<<<<<< HEAD
so how do I specify syntax for arbitrary refinements?
(x :- (x = 1) (x < 2) (x > 0))
What operations and forms are NOT quantified?
Q represents a quantified sub-program,
(x : T), (x)
What operations are quantified over the sub-program.
{(x : T), (x)}
does this result in a quantification of collections?
What if I want to specify the quantification of a collection?
The type of a collection of a bunch of things
what about a sequence?
A, B, Q
Q, A, B
((x : T), (x)), A, B
quantify over side effects?
yes.
Q, A, B
(f (g (h ((x : T), x))))
so in this case the quantification is propagated
How would I make a sequence by quantified?
(x : T), ((A, B, x), C)



how to create operations that do not affect context?
Macros don't affect context by default.
or do i need that if i have closures?
because closures capture everything.
Also i dont want to capture too small of a tree.
how would i implement green threads?
well you'd have to call a function that captures the continuation.
So there's a list of threads, a scheduler, and a function to capture a point and switch to another thread.
What does that look like?
You can turn all of them into a yield function over a list of continuations.
(threads <- {}),
(yield <- (c -> ))


I'd like to make an in-place insert operation.
(({1 3} \\ 1 2) = {1 2 3})


What if there's an expression which accepts anything?
Does that allow quantification?
(<- ((n : {'m *}) -> (f (n \ 2))),
(m (1 + Nat))
What about quantification as iteration?
Loop incrementing an array

how to loop?
Do I do tail call optimization? yes
can I also just do continuations? yes

(countdown <- (i -> (? (i > 0) (& <- (countdown (i - 1)) i))))
(countdown <- (i -> (? (i > 0) (countdown (i - 1)) i)))
(countdown <- (i -> (& \ 0 '(? (i > 0) (& <- (i <- (i - 1))) i))))
named let is such a convenient form. 
what's the equivalent of named let?
(& <- (loop <- `(a, (& <- loop))))
is there no equivalent of named let?
No but you can make it pretty easily.
((e : {'loop Symbol Expression}) -> ((e \ 1) <- (e \ 2)), (! (e \ 1)))



lets say I want to take the context so that I can always get a value back.
Contexts are bound by functions.
New functions create new contexts.
So when I use '&, it's referring to the immediate function context.
But it's not actually, it's referring the rest of the program.
So then how would I do threads?
use a FIFO proc list.

threads <- {}

sticking point, if the function boundary is the prompt, then what happens when 
you take the context at different points?
(f <- (x -> &, (g x), &, (h x))
it all equals the lambda with fixed arguments.
How to loop
(countdown <- (n -> 
	(? (n > 0) 
	   (n ~ (n - 1)), (& <- &)
	   n)))
or does it set control to a specific point?
what about returning, can you exit to a different place?
In a sequence, the context is the position at the sequence so 
(a, (x <- &), b, c, (y <- &), d)
((x \ 0) = (b, c, d))
((y \ 0) = (d))



Say I define some function on a collection and i call it 
(f <- ((n : Collection) -> n + {0})),
(f (1 2))
how does it know to treat '(1 2) as an expression not a collection?
type tags.
(1 2) is not the same as {1 2} because there's a type tag.



how to do pointers with one symbol?
there's two operations: derive the location of some data and refer to a location
@ is pointer operations.
trivial ((@ (@ x)) = x)
that looks nice
what about taking the address of a location?
(x <- (@ y)),
((@ x) = y)
if it's possible to take the address of an address then i can do it.
I have to do some type-level wrenching to do it.
((: y) = Location), (@ (y : *))
you can't upcast.
how to get the address of an address?
there's two types of the expression, 
[({'@ *} -> Location) ({'@ Location} -> *)]
what I need is ({'@ Location} -> Location)
so what kind of type-level wrenching can do this?
if I expect a location, then thats the operation that's applied
so now I have 
(({'@ *} -> Location) : Location)
(({'@ Location} -> *) : *)
(({'@ Location} -> Location) : Location)



where to use period?
its used as a decimal point in a symbol.
1.1
what notation should it be used for?
composition?
(f : Function), (g : Function), ((f . g) : Function)
use it to terminate a bunch of closing braces.
No that's harder to read.
Actually should I use it to look up names?
dot can be used as subscript or name lookup
it's overloaded based on whether you're handing it a number or a symbol.
(m <- {(x <- 1) (y <- 2) (z <- 3)}),
((m . 1) = 1),
((m . 'x) = 1)
no this sucks


Whats my syntax?
(math <- ({Number} + ['+ '- '* '/ '//] + [{Number} math]))
(logic <- ([{Boolean} {'- Boolean}] + ['/\ '\/] + [{Boolean} {'- Boolean} logic])
(collection-algebra <- ({Collection} + ['+ '- '/] + [{Collection} collection-algebra]))
(type-algebra <- ({Type} + ['+ '- '/] + [{Type} type-algebra]))
(access <- {'. [Number Symbol access]}), {Collection} + access
{Collection '. Symbol}
{Collection '/ *}
{Collection *}
({Symbol} * Collection + {'->} + Expression)
(Function + Collection)
{'@ *}
{'@ Location}
{Number ['< '>] Number}
{Type ['< '>] Type}
{* '= *}
{'? Boolean Program Program}
{'? Boolean Program}
(data <- {'|} + [{*} {* Natural}] + [{'|} data])



What are my basic types?
- Number
  - Integer
  - Natural
- Function
- Collection
  - Type
  - Expression
  - String
- Program
  - Expression
  - Symbol
- Character
- Data
  - Value
  - Reference
  - Byte



Is it possible to statically type code when you don't know the expression?
Depends.
I can verify functions just fine and same with lambdas, so it must be the same with contexts.
Contexts are lexical boundaries with lexical closures so stuff is only bound if it's declared lexically.
There's even syntax for it, (<- *)
So let's say I enter a function and I define a lambda and an expression.
(f : (n -> 
(<- ((e : {'a *}) -> (e . 2))),
(a 1)))
You can statically type if you have prior knowledge of the meaning of the code.
In a language like mine where the meaning of a phrase is completely contextual, you don't know.
It's equivalent to introducing a new word used in the next sentence.
That's fine in English and it's proven comprehensible by AI programs.
Should be fine here too.
Should I skip lisp though and just make a different kind?
I can make more node types than just the few involved in the Lisp AST.
Multi-typed AST.
That's the way to go.
An AST node with different semantics.
I can make a new constructor for it.
Can't be at the reader level though because the primitive reader only reads certain things.
That's okay though, I don't want every possible notation.
There's a difference between being able to conveniently extend syntax and having to include every possible syntax.



So it's impossible for a function to accept any expression and apply it.
This sucks.
In Lisp, everything is a function.
Maybe I'm doing it wrong.
Pattern matching over the structure of a thing without worrying about lookup or anything.
It's highly expressive, but difficult to interpret.
A faster interpreter would be a normal Lisp where you can dispatch on the first symbol reliably.
But I want an actual language, not a functional DSL.
I want to write variable sized math expressions (1 + 2 / 4 * 5)
I want to be able to write logic expressions (True /\ - False \/ True)
There's interleaved lookup though because you can't decide for any given context that a symbol is reserved as an operator.
This means that I can absolutely do (/\ <- True), (\/ <- False), ((/\ /\ /\) = /\)
No this isn't possible because symbols are resolved before the expression is evaluated so the previous expression would be {True True True} which isn't interpretable.
If a symbol isn't bound, then it's syntax.
That's a nice simple rule.



I need a data constructor so I can create vectors and segments of data.
That's (| Value | Value | Value | Reference | Byte 100 |)



where must a blank separate two things?
(Symbol Symbol) 
(Number Number)
If two Symbols or numbers are adjacent, they must be separated by a blank.




what's a program to read in a program model?
(-> 
 (program : _),
 (symbol : ""),
 (c : character),
 (c <- (read)),
 ({
   ((n : [Glyph Digit]) -> 
     (symbol <- (symbol + {c}))
   ((n : Blank) -> 
     (? (program = _) 
        (program <- symbol), (compute program)
	(? )))
((n : "(") -> )
((n : ")") -> )
((n : "[") -> )
((n : "]") -> )
((n : "{") -> )
((n : "}") -> )
((n : "\"") -> )
((n : "'") -> )
((n : Character) -> (error))
((n : _) -> (compute program))
} c)
)


how bad is it if I don't have complicated multiple operation forms?

What would be the type if I can't

(1 + (2 + ((3 - 1) / 1.5)))

Add together three collections
(Collection + (Collection + Collection))

logic problems
((True \/ True) /\ (False \/ True)) 
vs 
(True \/ True /\ False \/ True)



How do I talk about arrays?
I need a language for storage where I talk about how things are arranged spatially in the environment.
A Data language.
I can have a adjacent pair, or a vector.
This is different than a collection which is based on access and types.
Data has no type.
There's simple data and compound data.
Data is how you represent and organize information.
You have a single unit, a large unit, an a reference unit.
Call these 
Unit
Block
Reference

A Unit is the smallest single amount of data that can be stored.
A Block is the amount of data that can be operated on. It implies multiple 
A Reference is a unique abstract value corresponding to the location of a unit.
A Pair is to adjacent Data.
A Vector is a number of adjacent data.

Do I want the rest of the abstractions then? Yes.
It's nice that I have a language to talk about how things are represented, but
there's abstract concepts which should not be bound by format and storage requirements.
Or should they?
Yes.
The format of abstractions should be implementation dependent, but they should be extensible.
Or should I start from nothing with no type system?
That's dumb. I want a bunch of stuff built in.
There will always be some concept of digital storage.
My language is designed to be run on a computer rather than some abstract symbolic machine.
It's true that the symbolic part isn't even required.
But then how do you talk to the machine?



I don't like my language anymore.
There's a weird uncanny valley between the higher level abstractions and the lower level ones.
This should be fine though because I have functions to pass between each.
Also the point is that there is a sub-language to talk about how things are stored which is separate from the semantics of computation.
Just how there's a sub-language to talk about how numbers are worked.
This is actually suitable because you can make Unit, Block, and Reference be anything you need.



weirdness with the program model.
(1 + 1) ==> {1 '+ 1}
(({'a 'b} + {'c}) / 'b) ==> {{{'a 'b} '+ {'c}} / 'b}
Collections are part of the program model, but they're nominally typed as expressions.


How do I make undecideable syntax?
Easily.
(f : ((A) -> B)),
(f : ((A) -> C)),
(g : ((B) -> A)),
(g : ((C) -> A)),
(g (f A))
This is quantification though.
Do I need quantification? Yes.



Should I have two different languages for structuring data?
Yes because one kind of structure is about access an indirection, the other kind
is about relative position.
When I talk about data, I have a Unit, a Reference, and a Block.
A Block is some combination of Units and References.
Unit, Value, Register, Block.
A Block is made up of Units, Values, and Registers.
It is either a pair of adjacent data, or a vector of a single type of data.
(Unit | 100)
(Character : (Unit | 4))
(Character : Value)



Does a sequence form its own context? 
In other words, are the effects of the discarded expressions discarded as well as their results?
No. A sequence only means "this then finally that".
All of it occurs within the same context.
If you want to discard a context, then use a function,
((_ -> A, B, C)) 
that is a "code block"



What about effects?
I have a function, it does (f : (x -> x))
It doesn't affect anything, it just produces a value.
What about 
	(y <- 1), (f : (x -> (y <- x)))
that has an effect.
What about (f : (x -> (display x)))
that has an effect too.
I can't do effects because my language isn't abstracted from the effectful system.



Interfaces, Traits, and Typeclasses are ways to reason about the capabilities of a given abstraction.
"InTraClass" describes the idea of describing the capabilities of a type as the functions over it.
Take a type T, and an InTraClass M.
If M exposes the function f : M -> M, then 
f : T -> T means that T < M.
Normally InTraClasses are ad-hoc in that the implementations of the exposed 
capabilities can be defined at any point before the instantiation of the Intraclass is used.
Normal classes are not ad-hoc and the complete class definition must be given in a single declaration.
Interfaces and traits do not require this and only differ in classification of sub-type relations and inheritance.
I do not have interfaces because abstractions are not typed by the functions defined over them.

If I did want to make an Intraclass exposing a capability, I would have to write something like
Say I make some Intraclass "hash-able" with a capability "hash".
How would I make that for two types T and t such that both can be sub-types of hashable?
(T : Collection),
(t : Number),
(hash : ((T) -> Number)),
(hash : ((t) -> Number)),
(hashable : [(x : *), (? (hash x) x)])



How to talk about vectors?
[(m : Collection), (t : Type), (? ((:(m . (* : Number))) = t) m)]



how to talk about memory layout.
two things next to each other.
multiple of the same thing next to each other.
(Unit Unit)
(Unit 1000)
What if the model is a collection and then you instantiate data using the collection



how do I represent unbounded types?
should there even be a difference?
yes.
a quantified type is an unbounded type.
each type constructed is unique anyways.
so a continuous type is represented as a number of conditions which must be true.

(is-t <- (n -> (? (p /\ q /\ r) true false)))

so then do I need types at all?
is the type assertion even a part of the language or is it a macro?
It's a macro.
So is the debugger.
in fact, everything's a macro except for the basic language.
what about quantification?
nope.
what about simple type-checking for stuff like functions?
how do i do polymophism if the function doesn't work?
case matching.
you call the function on a case.
I am very stupid. Of course I need types.
Quantification is supposed to be one of the fundamental mechanics of my language.
If you can set a type constraint, then of course you can set a constraint without creating a variable binding.



how do I want to describe memory layout?
I want to talk about either two adjacent things or a thing that repeats.
i want to compose the two.


================================================================================
Matching algorithm--------------------------------------------------------------
================================================================================

let x be a value of type T.
Let there be a collection, m, with at least one element which is a function.
Take the collection, n, of all elements of m which are functions, (m / Function)
1. Search the collection for pre-images of the value x.
2. Search the collection for pre-images of the type T.
3. Search the collection for pre-images of a type where the value of x is the value of that type.


{1 2 3}
{Number Number Number}
(x : {Number Number Number})



A discrete or continuous type.
A discrete type is a collection of unique values.
A continuous type is a collection of conditions which must be true for a type.
I should be able to create a continuous type directly.
Here's some things that must be true.
That's just a refinement type though.
My type constructor is different. I can take the result of anything.

(m : Collection), (n : Number), (? ((:(m . n)) = K) m)

[[k]] is the same as [k]?
no because (x : [[k]]) is (x <- [k])
and (y : x), (y <- k)

so I can say 
(x <- (m : Collection), (n : Number), (? ((:(m . n)) = k) m))

so in (x <- (y <- 1), y)
does y persist in the context?
have I bound those?
I wish there was a way to make a temporary context.

(x <- ((_ -> (m : Collection), (n : Number), (? ((:(m . n)) = k) m))))



should quantification be effectful?
can I even make it effectful?
yes, via pointers.
(x <- {1}), (y <- (@ x)),
(n : ['a 'b 'c]), 
((* -> ((@ y) . 1 (((@ y) . 1) + 1))) n)
no because x is closed over and copied for each time the quantification is run.
it's not actually quantification if you can change what's true for each iteration.


What components of the language should not require arbitrary computation?
None, all facets of the language should allow arbitrary computations.
The langauge is simple enough where that's easy.
What about first class expressions?



A collection is not just a relation, it's also a resource constraint.
When a collection exists, so do all its elements.



I can't truly have higher order expressions... actually yes I can.
Expressions in my langauge are just maps between some syntax and some other syntax.
Unless I use compute, all functions are known because they can't be non-deterministically constructed.
Behavior may not be known, as in a polymorphic function, but that's okay.



I like the simplicity of cons pairs, but it's more efficient to use collections.
It supports vectors beyond a pair and random access.
Cons is actually implicit in the constructor.
(cons (cons 'a 'b) 'c) = {'a 'b 'c}
is an element separate or together with a collection?
That is to say, if a collection exists, does it imply that its elements exist?
YES IT DOES DON'T BE STUPID


I would love to express every algorithm in finite space and make resource allocation explicit.
Then I'm just left with C.
Especially with unrestricted dependent types, every stage of the computation process can require arbitrary space and time.



How do I make expressions that don't form their own contexts?
Or does each expression always have its own context?
Contexts can be discarded if they are never used.

What is {*}?
A collection containing anything.
How about [{*}]
the type of every collection containing anything.
((x : {*}) {0}) is this sound?



There's two types of types: discrete and continuous.
A discrete type can be represented as a listing.
A continuous type is represented as a program that verifies the type.
For a user-created continuous type, you have to specify the program which verifies the type.
What about quantification?
Saying for-all.
What if I can't use that?
Then I can't make refinement types.
So how do I make the type of numbers greater than 0?
Without quantification, I would have to make a recursive type like
(Couting <- []),(n -> (? (n > 0) (t + [n])), (n <- (n + 1)), (& <- &))
or I can say
(Counting <- ((_ -> (n : Natural), (? (n > 0) n))))
this is much more straightforward for a type definition.
I can get even easier,
(Counting <- (n : Natural), (? (n > 0) n))

Sequences form their own context.

(step1), (step2), (step3), (& <- &), (step4)
(n -> 
(n <- (n + 1))
(n <- (n + 1)))

What's the behavior when you call read?
you read in either a symbol, number, or a program which is computed to yield the read result.
you can also read in a character which reads in a single character of the character type.



how to make the type of an expression non-inferenceable?
Say an expression results in 1
what is non-inferenceable without using 'compute?
any non-recursive function stack is inferenceable.



what about skipping recursion?
Can I do that?
skipping recursion in favor of effects?
but i still want recursion.
how do I even do recursion?
the name inside the function is resolved after the name outside the function is resolved.
therefore when the function is engaged, it inherits the external binding of f.



what would a language look like that's not full of parentheses?

f = x in x + 1 .
f(1) .
y = 1, z = y  .
m = {1 2 y = 3 .} .
m / 1 .
n = m + {4} .
n = m .. 4 .

just more keywords that's all.
so could I define a language that's all keywords?

(f = (x y -> (x + y)))
f = x y -> x + y .


my language is harder than lisp. not everything is a list.
everything is a collection.
each collection has a counted number of elements.
Each element has a type.



what's my vector syntax?
(k .. n)
what's my matrix syntax?
(k .. n .. n)
how do I access them?
(V = ())
a matrix is just a vector with a length and a dimension.
it's an abstraction over vectors.
so I have a set, a vector, and a multiset.
do I need a vector if I can just have a multiset?
not really, all i need is a way of constructing a vector.
That's just 
(vector = (k n -> )

functions are control flow though so how do I take the context of a function before I enter into a sequence?
I use a sequence-less function definition.

(f = (k -> (m = &) m))

what's the type of a function then?

(+ (n : Nat), (Symbol .. n) 
   {'->}
   (m : Nat), (Expression .. m))

so if I want multiple

how to use | ?
Does it represent a type?
I have * _, but what about |
is that the context? no that's &
what about Any, Nil, Some?
no
what about data?
is it a block of data? no those are different sizes.
is it a storage type?
Unit type?
yes
Unit type is |
so now I can say
(Character = {| | | |})
oh that's actually kinda cool.
|__#_|
that describes a data



Nope, not doing it.



syntax?

sum		_ + _
		+ ...
difference	_ - _
		- ...
multiplication	_ * _
		* ...
division	_ / _
		/ ...
modulus		_ // _
disjunction	_ /\ _
conjunction	_ \/ _
negation	- _
constrain	_ : _
equality	_ = _
less		_ < _
greater		_ > _
less or		_ >= _
greater or	_ <= _
inequal		_ /= _
cardinality	# _
address		@ _
supertype	: _
function	_ -> _
collection	{ ... }
vector		_ .. _
type		[ ... ]
access		_ . _
application	_ _



what if storage types have special semantics.
what if I do a collection of {Byte Byte Byte}?
are these pointers to bytes? or actual bytes?
They're actual bytes.
storage types don't require indirection because they are stored directly.
even if I swap types around.



What fundamental capabilities do I need for my implementation?
I need the compute loop.
I need a matching function.
I need a constructor for each of the default functions.



What about qualitative types?
Say I want the type of a sorted collection.
It can be completly nominal.
(sorted = [Collection]),
(sort = ((M : Collection) -> sorted))



All expressions for all possible languages have a common grammar. 
What does this look like though?
Is it possible to simply talk?
No because you don't need multiple forms of each expression.
It's trivial to start with something more basic.
Is it possible to just use functions with no punctuation?
Not as long as there's macros.
f g h x
is fine but 
(f (g (h x))) 
works much better.
parens allow you to be extremely terse.
being terse is nice, but playing "code golf" like you do in the APL family obscures the meaning of the program.



unbounded types break the type system.
every primitive in the language should at least halt XD
Primitive types are always structural.
Because you can't quantify over a structure when all instantiations of a 
structure are structurally identical.
For instance: 
(T = {a b}),
(x = {a b}), (y = {a b})

what about refinement types though?
[(n : Number), (? (n < 10) n)]
[(f : Function), (n : Number), (f n)]
these require quantification and cannot be typed as a number.
Because a number is a structure.
Lets say
(T : [m n]),
(t = [(p : {T}), (? (p / m) p)])

What is the type of a number?
The constructor takes a symbol and converts it to a number.
(new-number : Function)
(Number : [(s : Symbol), (new-number s)])



(1 : 1)
(1 : Number)

quantification is separate from unbounded types.
normal bounded types are just enumerations. 
[a b c] as a predicate is 
(x -> (? ((x = a) \/ (x = b) \/ (x = c)) x))

(x : *), (? (\/ (x = a)(x = b)(x = c)) x)

in the first version, the deciding program is packaged as a lambda.
in the second version, the deciding program is implied via quantifiation.
the problem with quantification is that the resulting type may not have any 
correspondence to the independent variables.
(n : T), (m : t), {n m}
vs
(m -> (? (((# m) = 2) /\ (m / T) /\ (m / t)) m))


Macros and type checking are different. Or are they?
({* ': *} -> )



so how do I specify syntax for arbitrary refinements?
Not sure.
What algorithm do I need for enforcing properties?
I have a property P. It specifies one of...
-	the result of an expression
-	the type of an element
-	the image of a function
-	the pre-image of a function
-	a subtype
-	a supertype


so arbitrary refinements are built up as a predicate on a type, forming a new subtype.
the syntax uses a semicolon
(T ; (x -> (? (P x) x)))
this creates a subtype of T

how to use whitespace with structures.
either nest or indent.

{A B {C D {E} F} G}

A B 
 C D
  E
 F
G


So how would this typed function be presented?

((x : T) -> ((y = (l n)), (k x y) : (T | (x -> (P x)))))


 x : T
->
  y = 
   l n
  ,
   k x y
  :
   T | 
    x -> 
     P x

So then structure is nested by how many spaces to the right the line begins.
There's still the issue of stuff being on the same line though. 
With each new sub-expression on its own line, stuff looks terrible.

X : T -> 
 y = l n,
 k x y : 
 T | x -> P x

but this isn't clear so add parens back in

(x : T) ->
 y = (l n), k x y 
 : 
  T | 
   x -> (P x)

so what are my actual rules?
a new line denotes a new expression in every case.
leading blank space denotes a sub expression.
successive sub-expressions can be nested by adding at least one more blank 
space leading the next line.

Delimiting braces imply a leading space which can be omitted from the following
lines contained in the brace pair. Therefore 

{
 a b c
 x y z
}
becomes

{ a b c
x y z }


two line breaks with no tokens in between signify the top level end of an 
expression

"Bubble Sort",
(bs = (list -> 
	(p = 0),
	(? 
	((list / p) > (list / (p + 1)))
		(tmp = (list / p)),
		(list / p (list / (p + 1))),
		(list / (p + 1) tmp), 
		(p <- (p + 1)),
		(bs list)
	list)))

"Bubble Sort" , bs = (list -> 
p = 0,
? 
 (list / p) + (list / (p + 1))
 tmp = (list / p),
 list / p
          list / (p + 1)
 list / (p + 1) tmp,
 p <- (p + 1),
 bs list
 list
 
  
actually, this is a terrible idea, indentation doesn't make lisp any more 
readable. It just makes it harder to format and harder to extend.
Case in point, most languages do not associate line breaks with grammar.
line breaks and indentation just serves as a higher abstract comprehension aid,
same as choice of variable names.

so what I want is lisp but with xpath and xpointer API's.
I kind of already have xpath since everythin is a dictionary.

lisp, but with no parens.
how do I do that?
with xml

xml is a good data format but it's verbose.
plus i don't need different types of expressions....
or do I?
expressions are a way of writing something, but they aren't necessarily related to a program's semantics
xml is heavier weight.
expressions are heavyweight.
each tag is more of a dsl fragment.
hard to read and write.
plus attributes are kind of useless, especially if I want interactivity.
the whole thing needs to be expression based, with no forward declaration, 
and terse so its easy to type.

That means no parens
i give up syntax for a fast language.
trade extensibility for speed.
but I do want speed.
at the same time, it would be really cool to have everything dynamic.
syntax, types, expressions, everything.


I want whitespace delimiters.
this requires three things.
Each token must now be prefixed with some whitespace annotation of nesting.
double nesting and allowance for formatting must be dealt with.
nested single-line expressions must be dealt with.

for visual aid, backtic represents a newline and underscore represents leading space
take a nested structure.

((a) b c (d e (f) g) h)

`_a `b `c `_d `_e `__f `_g `h

 a
b c
 d e
  f
 g
h

kind of ugly and takes up too much vertical space

how to make it not ugly?
i guess the point is that delimiters for each expression are necessary unless 
you arrange for a grammar.
there has to be an in-between though.
how about regular expressions?
no.
everyone complains about parentheses but it's not actually that bad.
or just deal with juxtaposition.
except then you can only do prefix notation.
delimiters and pattern matching seems the best way.
no prefix notation.
add parsers to the deault expressions so that you don't need so many parens.
What's my basic language.
You can construct booleans, numbers, functions, collections, and types.
You can perform arithmetic with numbers.
You can apply and compose functions.
You can perform set operations on collections.
You can destructure collections.
You can perform first order logic algebra on logic operators.
You can construct a type from a predicate.
You can construct a supertype from two types.


should I have effects?
Typed effects or effect systems?
No.
I already have everything I need wth first class contexts.
Hiw would I do effect handlers?
Set up a context to call the function in.
But how do you do it without passing the context to the function as a parameter?
easy, you bind the handlers in the context where the function is defined.
then you don't have to do stack unwinding.

Finite types just satisfy some kind of equality.
Saying [A B C] is the same as 
(* | (n -> ((n = A) \/ (n = B) \/ (n = C))))

macros.
set the handler in the context outside the function call.
or say that the handler is bound where the function is defined.

here's an interesting problem with my expressions: how do you know what is a 
variable and what is punctuation.
simple, if it's punctuation, then it's not used as a variable by the rewrite 
step.

how does a return work when functions don't return?

(f = (x -> 
 x))

isn't that the same as 
(f = (x -> (& <- x)))

This is kinda dumb though.


So what if I define 
(IsEven = (Number | (n -> (0 = (n mod 2)))))
and then I have a function 
(f : ([IsEven] [IsEven] -> IsEven))
(f = (n m -> n + m))
There's no way for the compiler to know that it can get an IsEven out of 
addition. So I would have to specify those properties.

(EvenResult = [IsEven ((n : IsEven) + (m : IsEven))])

what would be my syntax without that?
literally the same as I have it, just with pesky precedence rules.
I don't want precedence rules.
It's just a scripting language.
You can add parentheses, it's fine.
Here's the shortcut though, the comma doesn't require parens.

(x : t), (f x)
becomes
(x : t, f x)
and at the top level becomes
x : t, f x


what about linear types?
I need a way to figure out when to copy and when to overwrite.
That's the difficult part.
There should be a semantic for it so behavior is predictable.


Rule 1: New objects can only be added to the active function.
Rule 2: Objects cannot change size.
Rule 3: Objects are not discarded until their function scope exits.

So how do I do data structures?
Put everything in the same context.
Use object abstraction.

I have three functions, f, g, and h that are monadic.
How do I do monad composition?

(do f g h with M)

monads are just higher order functions with data structures.
what about effects?
effects are just the same as monads but the focus is on control rather than
sequencing lazy computations.
it should be possible to create a typed effect system from scratch as long as I can specify a first class resume.
a resume is definitely just a lambda. 
the problem is changing the continuation.
how do I do that with first class contexts?

simple example.
i want to set a context which will be jumped to on a failure.
it should be dynamic.
actually if it's lexical, it's typeable since all structure is known during compilation.

how do I implement throw?
The problem is it's dynamic. 
If I don't have dynamic prompts, then I don't have actual continuations.
It's fine to do it dynamically though, you just have to thread the context through everything.

Can I do green threads statically?

(choose (p : Collection))

how can I do sytax without mutation.
That's such an important part.
Or I can set arbitrary stuff using equalities.
How would I do addition then?
It's structurally typed so,

a : Number, b : Number, '(a '+ b) = (sum a b)
'(f )

pattern matching using independent variables.
interesting.

a : T, b : t, 
? (c : {a b}) true false

So I can't mutate bindings.
You set it once, then it's done after the context exits.

how do I set up syntax then?
The whole entire evaluation model was about composing contexts.
Maybe that's the mechanism, but mutating it is not allowed.


If a function can replace its context, is that all I need?

Lets say you want to throw.

try {
	throw 1
}
catch(x) {
	x + 1
}

In my langauge I would have

catch = (x -> x + 1)
f = (_ -> (! (catch 1)))


A handler can resume multiple times, and run code after the try body.

try {
	return 1 + perform e
}
with e (x) {
	x = resume(1) + resume(1)
	m = resume(x)
	return m
}
where each (resume 1) yields n = 1 + 1
1 + 1 + 1 + 1 + 1 + 1

e = (k -> (
	x = ((k 1) + (k 1)),
	m = (k x),
	m
))
f = (_ -> (
	e (x -> (x + 1)))
))

deciding a type can take any amount of time.
I want syntax to be constant time.
Well that would be lisp where everything's a lookup.
What about functions that take and return expressions?
If all functions happen at runtime then you can't do macros.
Do you need macros if everything's a function?
Yes, you still do so you can write easier stuff.



Do I want context to have mutable state?
No. rather than mutable state, I want to express something else.
What if I want to add two numbers, how would that work?

n : Number, m : Number, 
(Expression : {n '+ m}) = (sum n m)

so you use unbound variables to express a rewrite transform.
how would this work with other stuff?

f : Function, x = 'k,
(Expression : {f x}) = 'l

which is saying (f : ('k -> 'l))

this is different than expressions as objects.
it's more expressive though.

I want to say something like 
x : t, y : T,
<- ({x '~ y} -> (op x y))
what are the semantics for this?

An unbound variable represents a place and everywhere that it's used 
corresponds to that place.
It's up to the compiler to figure out how to get to that place.

if I do 
(<- ('k -> 'l))
can i then do

<- ('k -> 'l),
f = (x -> (& 'k))



=======================================================================================
All about functions
=======================================================================================
functions are declared as some parameter names followed by an arrow, followed by
some expressions using the parameter names.
(x y -> (x + y))
you can call a function by putting the arguments after the function
((x y -> (x + y)) 1 1)
the number of parameters passed must match the number of variables declared
each parameter has a type constraint which the objects passed in must follow.


=======================================================================================
all about collections
=======================================================================================
collections behave as indexed multisets.
it allows O(1) complexity access to any member of the collection.
you make a collecction by listing objects in curly brackets.

You can add, subtract, multiply, and divide collections.
you can also access elements by index, or by type.


=======================================================================================
how do I do my macros?

There should be a simple syntax which macros will reduce to.
functions and collections.

so you define some pattern, and a function that gets applied to it.
if the function returns null, then compilation failed.
the function has access to everything so error messages can be part of it.
so just like a type refinement, (T | (x -> x))
I do a syntax transform 
({'expression OperandType} => Function)

yeah this works.
What does it return?
Nothing. It isn't an actual expression, it lifts code instead.
What would I even do with macro objects?
I would put them in different contexts.
I can declare a macro and then put it somewhere.
This lets me create importable syntax.
What does it mean to put a macro in a context though?
Now there needs to be another operator to establish a macro in a lexical context.

which means I would just declare a macro as a normal function.
what would a macro symbol look like?
(<= )
and that means that a function is exposed as a macro.


what are first class macros?
You bind them in a context. 
But what a context is may depend on a macro being bound.